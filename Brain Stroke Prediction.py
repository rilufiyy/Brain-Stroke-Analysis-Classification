# -*- coding: utf-8 -*-
"""Sri Lutfiya Dwiyeni_Advanced ML Classification Assignment_AIML 8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vcxVVsO9LPh0kqLt7z9Y4q3Wd2_3VBPV

# Load Libraries
"""

pip install scikeras

from zipfile import ZipFile
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import GridSearchCV, train_test_split
from imblearn.combine import SMOTEENN, SMOTETomek
from imblearn.over_sampling import SMOTE
from collections import Counter

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from keras.models import Sequential
from keras.layers import Dense, Dropout
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report

import warnings
warnings.filterwarnings('ignore')

"""# Load Dataset"""

with ZipFile('brain stroke.zip', 'r') as zip:
  zip.extractall()

df = pd.read_csv('/content/healthcare-dataset-stroke-data.csv')

df

"""## Data Description
| No | Column Name        | Description |
|----|--------------------|-------------|
| 1  | id                 | Unique identifier for each individual. |
| 2  | gender             | Gender of the individual (e.g., Male, Female, Other). |
| 3  | age                | Age of the individual in years. |
| 4  | hypertension       | Indicates whether the person has hypertension (1 = Yes, 0 = No). |
| 5  | heart_disease      | Indicates whether the person has a heart disease (1 = Yes, 0 = No). |
| 6  | ever_married       | Marital status of the individual (e.g., Yes, No). |
| 7  | work_type          | Type of work the individual does (e.g., Private, Self-employed, Govt_job, etc.). |
| 8  | Residence_type     | Type of residence (e.g., Urban, Rural). |
| 9  | avg_glucose_level  | Average glucose level in the blood. |
| 10 | bmi                | Body Mass Index of the individual. |
| 11 | smoking_status     | Smoking status (e.g., formerly smoked, never smoked, smokes, Unknown). |
| 12 | stroke             | Indicates whether the individual has had a stroke (1 = Yes, 0 = No). |

"""

df.describe()

"""**Penjelasan insight:** Dataset brain stroke memiliki 5110 baris, namun kolom BMI hanya memiliki 4909 data, artinya ada 201 nilai yang hilang. Dengan rincian data describe tiap kolomnya sebagai berikut:
1. age
    - Rata-rata usia responden adalah 43 tahun, dengan rentang usia dari 0.08 tahun (bayi) hingga 82 tahun.
    - Mayoritas (50%) berusia di bawah 45 tahun, jadi sebagian besar peserta tergolong usia produktif.
2. Hipertensi dan Penyakit Jantung
    - Hanya sekitar 9.7% yang memiliki hipertensi dan 5.4% yang memiliki penyakit jantung. Artinya sebagian besar pasien sehat dari dua kondisi tersebut.
3. Rata-rata Glukosa (avg_glucose_level)
    - Nilai rata-rata 106.15, dengan rentang 55.12 hingga 271.74.
    - Beberapa nilai cukup tinggi, menunjukkan adanya outlier atau individu dengan kadar gula tinggi (potensi diabetes).
4. BMI (Body Mass Index)
    - Rata-rata 28.89, termasuk kategori overweight (berdasarkan standar WHO). [Link Source WHO BMI Category](https://www.who.int/news-room/fact-sheets/detail/obesity-and-overweight).
    - Nilai maksimum 97.6 menunjukkan kemungkinan adanya data ekstrem.
5. Stroke
    - Hanya 4.87% dari total data yang mengalami stroke, hal ini menunjukkan ketidakseimbangan kelas (imbalanced data) antara penderita dan non-penderita.

# Data Preprocessing (Data Wrangling)

## 1.1 Duplicate Data Checking
"""

dupe = df[df.duplicated()]
print("Duplikat di seluruh baris data:")
print(dupe)

"""**Penjelasan insight:** Setelah dilakukannya pengecekan untuk apakah terdapat duplikasi pada dataset, terlihat bahwa tidak ada duplicate pada dataset brain stroke.

## 1.2 Missing Value Checking and Handling
"""

df.info()

df.isna().sum()

"""**Penjelasan insight:** Berdasarkan output informasi tentang dataset di atas, diperoleh bahwa dataset berisi 5110 baris dan 12 kolom. Terdapat missing value pada kolom bmi sebanyak 201 baris yang hilang pada kolom tersebut."""

# Handling Missing Value
df['bmi'] = df.groupby('gender')['bmi'].transform(lambda x: x.fillna(x.median()))

df.isna().sum()

df.head()

"""**Penjelasan insight:** Setelah dilakukannya handling missing value pada kolom bmi dengan cara mengisi nilai yang hilang menggunakan median bmi berdasarkan gender, sekarang sudah tidak ada lagi missing value pada dataset brain stroke. Saya memilih melakukan imputasi nilai median BMI berdasarkan gender karena pada dasarnya laki-laki dan perempuan memiliki perbedaan komposisi tubuh, yang artinya BMI pada gender tertentu memiliki karakteristik sendiri. Sehingga nilai median BMI yang dihitung secara terpisah lebih mewakili kondisi sebenarnua dibandingkan jika memakai satu nilai median keseluruhan. Dengan menggunakan imputasi nilai ini, distribusi data masih terlihat realistis, tidak terjadinya bias terhadap salah satu kelompok gender, dan karakteristik individu tetap terjaga. Oleh karena itu dataset brain stroke ini bisa digunakan untuk analisis selanjutnya menggunakan model Machine Learning tanpa kehilangan informasi penting yang dibutuhkan dalam pemodelan."""

df.describe()

"""## 1.3 Outliers"""

num_cols = ['age', 'avg_glucose_level', 'bmi']

plt.figure(figsize=(12, 5))
for i, col in enumerate(num_cols, 1):
  plt.subplot(1, 3, i)
  sns.boxplot(y=df[col], color='skyblue')
  plt.title(f"Boxplot of {col}")
  plt.xlabel('')
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Pada output di atas, terlihat bahwa terdapat outlier pada kolom 'avg_glucose_level' dan 'bmi', namun outlier-outlier tersebut tidak perlu dihapus ataupun diubah karena masih mewakili kondisi nyata pasien pada dataset, saya hanya melakukan penanganan outlier pada bmi yang kurang dari 15 karena bisa memengaruhi model prediksi dan menyebabkan bias. Jika outlier tersebut dihapus justru bisa mengurangi variasi informasi pada dataset dan membuat model dapat kehilangan informasi penting untuk mendeteksi risiko stroke otak pada kondisi ekstrem, misalnya pasien dengan BMI atau glukosa yang tinggi."""

# Imputasi nilai BMI < 15 dengan median BMI per gender
median_bmi_gender = df.groupby('gender')['bmi'].median()

for gender, median_val in median_bmi_gender.items():
    df.loc[(df['gender'] == gender) & (df['bmi'] < 15), 'bmi'] = median_val

num_cols = ['age', 'avg_glucose_level', 'bmi']

plt.figure(figsize=(12, 5))
for i, col in enumerate(num_cols, 1):
    plt.subplot(1, 3, i)
    sns.boxplot(y=df[col], color="skyblue")
    plt.title(f'Boxplot of {col}')
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Setelah dilakukan pengecekan ulang menggunakan boxplot, distribusi data pada ketiga variabel numerik menunjukkan hasil yang wajar. Variabel age tampak normal tanpa adanya outlier ekstrem, menandakan data usia telah terdistribusi secara proporsional. Pada variabel avg_glucose_level, masih terdapat beberapa titik outlier di bagian atas, namun hal ini dapat dianggap valid secara medis karena kemungkinan merepresentasikan individu dengan kadar glukosa tinggi atau pasien diabetes. Sementara itu, pada variabel bmi, setelah dilakukan imputasi untuk nilai kurang dari 15 berdasarkan median tiap gender, bagian bawah boxplot menjadi bersih dari nilai tidak wajar. Meskipun masih terdapat beberapa nilai ekstrem di atas (sekitar 60-90), hal tersebut masih masuk akal karena dapat menggambarkan kasus obesitas berat, bukan kesalahan data.

## 1.4 Drop Features
"""

X = df.drop(['stroke', 'id'], axis=1)
y = df['stroke']

X

y

X_categorical = X.select_dtypes(exclude="number")
X_numerical = X.select_dtypes(include="number")

"""## 1.5 Categorical Data"""

X_categorical

X_categorical_encoded = pd.get_dummies(X_categorical, drop_first=True)
X_categorical_encoded

"""**Penjelasan insight:** Setelah dilakukan proses one-hot encoding, tiap kolom kategorikal diubah jadi bentuk biner (True/False) supaya bisa dibaca model machine learning."""

encoding_columns = X_categorical_encoded.columns
encoding_columns

"""**Penjelasan insight:** Berdasarkan output di atas dapat terlihat bahwa mayoritas data didominasi oleh kategori umum seperti gender_Male, sementara kategori gender_Other sangat sedikit. Sebagian besar responden juga sudah menikah (ever_married_Yes) dan bekerja di sektor Private atau Self-employed, sedangkan kategori seperti “Children” atau “Never worked” jumlahnya sangat kecil. Untuk tempat tinggal, proporsi antara Urban dan Rural biasanya hampir seimbang. Di sisi lain, variabel smoking_status juga menarik, karena kebanyakan orang termasuk kategori “never smoked”, diikuti “formerly smoked”, dan hanya sedikit yang masih aktif merokok. Secara keseluruhan, hasil encoding ini sudah siap digunakan untuk modeling dan bisa membantu melihat pengaruh faktor gaya hidup serta sosial terhadap risiko stroke.

## 1.6 Numerical Data
"""

num_scaler = StandardScaler()
X_numerical_scaled = num_scaler.fit_transform(X_numerical)
X_numerical_scaled

"""**Penjelasan insight:** Setelah dilakukan standardisasi dengan StandardScaler, semua fitur numerik kini memiliki skala yang sama, yaitu dengan rata-rata mendekati nol dan standar deviasi sekitar satu. Nilai positif menunjukkan data di atas rata-rata, sedangkan nilai negatif menunjukkan data di bawah rata-rata.

## 1.7 Combined Data
"""

X_numerical_scaled = pd.DataFrame(X_numerical_scaled, columns=X_numerical.columns)
X_numerical_scaled

X_processed = pd.concat([X_numerical_scaled, X_categorical_encoded], axis=1)
X_processed

"""**Penjelasan insight:** Output di atas merupakan hasil preprocessing yang sudah melalui standarisasi untuk kolom numerik dan encoding untuk kolom kategorikal. Kolom numerik seperti age, avg_glucose_level, dan bmi sekarang memiliki nilai rata-rata sekitar 0 dengan sebaran yang seragam (hasil dari StandardScaler), sehingga tidak ada lagi perbedaan skala antar fitur. Kolom kategorikal seperti gender_Male, work_type_Private, atau smoking_status_smokes sudah diubah menjadi format boolean (True/False) melalui one-hot encoding, membuat model lebih mudah memahami perbedaan kategori.
Secara keseluruhan, dataset ini sudah bersih, terstandarisasi, dan siap untuk proses pelatihan model prediksi stroke.

# Exploratory Data Analisis

## Distribusi Pasien Stroke berdasarkan Usia
"""

plt.figure(figsize=(12, 6))
sns.histplot(
    data=df[df["stroke"] == 1],
    x="age",
    hue="gender",
    multiple="stack",
    bins=30,
    kde=True,
    palette="Set2",
    edgecolor="black",
    linewidth=1.5
)

plt.title("Stroke Patients' Age Distribution", fontsize=16)
plt.xlabel("Age", fontsize=12)
plt.ylabel("Count", fontsize=12)
sns.despine(left=True, bottom=True)
plt.show()

"""**Penjelasan inisght:** Berdasarkan output di atas, diperoleh beberapa insight dengan rincian sebagai berikut:
* Distribusi usia pasien stroke tampak condong ke kanan (right-skewed), menandakan bahwa kasus stroke lebih banyak terjadi pada usia lanjut.
* Sebagian besar pasien berada pada rentang usia 55 hingga 80 tahun, yang menunjukkan kelompok usia dengan risiko stroke lebih tinggi.
* Baik pasien laki-laki maupun perempuan menunjukkan pola usia yang serupa, namun jumlah pasien perempuan sedikit lebih banyak pada usia di atas 70 tahun.
* Terdapat juga beberapa pasien berusia muda (di bawah 40 tahun), yang mengindikasikan bahwa stroke tidak hanya menyerang lansia tetapi juga bisa terjadi pada usia muda.

## Distribusi Pasien Stroke berdasarkan Gender
"""

df['stroke'] = df['stroke'].map({0: 'No', 1: 'Yes'})

labels = ["Male", "Female"]
size = 0.5

stroke_gender_counts = df[df["stroke"] == "Yes"]["gender"].value_counts(ascending=True)

wedges, texts, autotexts = plt.pie(
    [stroke_gender_counts.values[0], stroke_gender_counts.values[1]],
    explode=(0, 0),
    textprops=dict(size=14, color="white"),
    autopct="%.2f%%",
    pctdistance=0.72,
    radius=0.9,
    colors=["skyblue", "lightcoral"],
    shadow=True,
    wedgeprops=dict(width=size, edgecolor="black", linewidth=2),
    startangle=100
)

plt.legend(
    wedges,
    labels,
    title="Gender",
    loc="center left",
    bbox_to_anchor=(1, 0, 0.5, 1),
    edgecolor="black"
)
plt.title("\nPasien Stroke berdasarkan Gender", fontsize=15)
plt.show()

"""**Penjelasan insight:** Berdasarkan output di atas, diperoleh bahwa sebanyak 43.37% pasien dengan gender laki-laki mengalami stroke, sedangkan sebanyak 56.63% lainnya bergender perempuan merupakan pasien yang mengalami stroke.

## Distribusi Pasien Stroke berdasarkan Status Perokok
"""

smoke_counts = df['smoking_status'].value_counts()

colors = ['#6B3E26', '#F18F01', '#719872', '#F15A29']

plt.figure(figsize=(12, 6))
plt.pie(
    smoke_counts,
    labels=smoke_counts.index,
    autopct='%1.2f%%',
    startangle=90,
    colors=colors,
    textprops={'color': 'black', 'fontsize': 12},
    wedgeprops={'edgecolor': 'black', 'linewidth': 2},
)

center_circle = plt.Circle((0, 0), 0.70, fc='white', edgecolor='black', lw=2)
fig = plt.gcf()
fig.gca().add_artist(center_circle)

plt.title("Pasien Stroke berdasarkan Status Perokok", fontsize=18, color='black', pad=20)

plt.legend(
    smoke_counts.index,
    title="Smoking Status",
    loc="center left",
    bbox_to_anchor=(1, 0, 0.5, 1),
    edgecolor="black"
)

plt.show()

"""**Penjelasan insight:** Berdasarkan output diahram di atas, diperoleh bahwa sebagian besar pasien stroke berasal dari kelompok yang tidak pernah merokok (37,03%), diikuti oleh kelompok dengan status merokok tidak diketahui (30,22%). Sementara itu, pasien yang pernah merokok menyumbang sekitar 17,32%, dan yang masih merokok aktif sebesar 15,44%. Hasil ini menunjukkan bahwa meskipun ada pasien stroke yang memiliki riwayat merokok, proporsi terbesar justru berasal dari kelompok yang tidak pernah merokok, sehingga faktor lain di luar kebiasaan merokok kemungkinan juga berperan penting terhadap risiko stroke.

## Distribusi Pasien Stroke berdasarkan Status Pernikahan
"""

plt.subplots(figsize=(8, 4))

colors = ["#6baed6", "#c6dbef"]

p = sns.countplot(
    y=df[df["stroke"] == "Yes"]["ever_married"],
    order=df[df["stroke"] == "Yes"]["ever_married"].value_counts(ascending=False).index,
    palette=colors,
    edgecolor="black",
    linewidth=2,
    saturation=1
)

p.set_title("\nPasien Stroke berdasarkan Status Pernikahan\n", fontsize=16)
p.set_ylabel("Marital Status", fontsize=14)
p.set_xlabel("\nTotal", fontsize=14)
p.set_yticklabels(p.get_yticklabels(), rotation=0)

for container in p.containers:
    p.bar_label(
        container,
        label_type="center",
        padding=6,
        size=14,
        color="black",
        rotation=0,
        bbox={
            "boxstyle": "round",
            "pad": 0.2,
            "facecolor": "#f9d9a8",
            "edgecolor": "black",
            "linewidth": 2,
            "alpha": 1
        }
    )

sns.despine(left=True, bottom=True)
plt.show()

"""**Penjelasan insight:** Berdasarkan output di atas, diperoleh bahwa sebagian besar pasien stroke adalah pasien yang sudah menikah, dengan jumlahnya yaitu mencapai 220 orang dibandingkan dengan 29 pasien yang belum menikah. Hal ini kemungkinan besar berkaitan dengan faktor usia, karena kelompok usia menikah umumnya memiliki risiko stroke yang lebih tinggi.

## Distribusi Pasien Stroke berdasarkan Tempat Tinggal
"""

plt.figure(figsize=(7, 7))

palette = ["#A7C7E7", "#3A6EA5"]

labels = ["Urban", "Rural"]
size = 0.5

values = df[df["stroke"] == "Yes"]["Residence_type"].value_counts(ascending=False).values

wedges, texts, autotexts = plt.pie(
    values,
    explode=(0, 0),
    textprops=dict(size=20, color="white"),
    autopct="%.2f%%",
    pctdistance=0.72,
    radius=0.9,
    colors=palette,
    shadow=True,
    wedgeprops=dict(width=size, edgecolor="black", linewidth=4),
    startangle=85
)

plt.legend(
    wedges,
    labels,
    title="Residence Type",
    loc="center left",
    bbox_to_anchor=(1, 0, 0.5, 1),
    edgecolor="black"
)
plt.title("\nPasien Stroke berdasarkan Tempat Tinggal", fontsize=18)
plt.show()

"""**Penjelasan insight:** Berdasarkan output visualisasi di atas, diperoleh bahwa, pasien yang mengalami stroke di daerah kota (urban) lebih banyak, yaitu dengan persentase sebesar 54.22%. Sedangkan pasien yang tinggal di daerah pedesaan (rural) sebesar 45.78%. Hal ini bisa menunjukkan bahwa gaya hidup masyarakat perkotaan dapat memengaruhi tingkat terkena nya penyakit stroke, seperti stres tinggi, pola makan tidak sehat, dan kurang aktivitas fisik, hal tersebut berpotensi meningkatkan risiko stroke dibandingkan dengan masyarakat di pedesaan.

## Distribusi Pasien Stroke berdasarkan BMI dengan Kategori Gender
"""

plt.figure(figsize=(12, 4))
p = sns.histplot(data=df[df["stroke"] == "Yes"], x="bmi", hue="gender",
                 multiple="stack", palette=palette[0:2], kde=True,
                 bins=30, alpha=1, fill=True, edgecolor="black", linewidth=3)

p.axes.lines[0].set_color(palette[1])
p.axes.lines[1].set_color(palette[0])
p.axes.set_title("\nDistribusi Pasien Stroke berdasarkan BMI\n", fontsize=20, fontweight='bold')
p.set_ylabel("Count", fontsize=14)
p.set_xlabel("\nBMI", fontsize=14)
p.tick_params(axis='both', labelsize=12)
sns.despine(left=True, bottom=True)

plt.show()

"""**Penjelasan insight:** Dari grafik tersebut menunjukkan distribusi BMI (Body Mass Index) pada pasien stroke berdasarkan jenis kelamin (gender). Berikut merupakan detail insight yang dapat diperoleh dari grafik visualisasi di atas:
* Sebagian besar pasien stroke memiliki BMI di kisaran 25 hingga 30, yang termasuk kategori overweight (berat badan berlebih).
* Jumlah pasien dengan BMI normal sekitar 18 hingga 25 lebih sedikit, dan semakin menurun pada BMI di atas 35 tergolong obesitas berat.
* Pola distribusi antara laki-laki dan perempuan relatif mirip, tetapi perempuan sedikit lebih banyak pada rentang BMI tinggi (≥30).

Dapat disimpulkan bahwa, kebanyakan pasien stroke memiliki BMI yang tergolong overweight hingga obesitas, yang mengindikasikan bahwa kelebihan berat badan menjadi salah satu faktor risiko yang umum pada penderita stroke.

## Distribusi Pasien Stroke berdasarkan Status Hipertensi
"""

plt.figure(figsize=(10, 4))
p = sns.countplot(
    y=df[df['stroke']=='Yes']['hypertension'],
    order=df[df['stroke']=='Yes']['hypertension'].value_counts(ascending=False).index,
    palette=palette[0:2],
    saturation=1
)
p.axes.set_title("\nPasien Stroke berdasarkan Status Hipertensi\n",fontsize=22)
p.axes.set_ylabel("Status",fontsize=16)
p.axes.set_xlabel("\nTotal",fontsize=16)
p.axes.set_yticklabels(p.get_yticklabels(),rotation = 0)
for container in p.containers:
    p.bar_label(container,label_type="center",padding=6,size=15,color="black",rotation=0,
    bbox={"boxstyle": "round", "pad": 0.2, "facecolor": "#e0b583", "edgecolor": "#1c1c1c", "linewidth" : 4, "alpha": 1})


sns.despine(left=True, bottom=True)
plt.show()

"""**Penjelasan insight:** Berdasarkan output di atas, terlihat bahwa dari seluruh pasien stroke, sebagian besar tidak memiliki hipertensi sebanyak 183 pasien dengan ditandai dengan status = 0, sedangkan untuk pasien stroke yang memiliki hipertensi (status = 1) berjumlah lebih sedikit, yaitu sekitar 66 orang. Hal ini menunjukkan bahwa meskipun hipertensi dikenal sebagai salah satu faktor risiko utama stroke, dalam dataset ini lebih banyak pasien stroke yang tidak terdiagnosis hipertensi. Dengan demikian, faktor lain selain hipertensi kemungkinan juga berperan penting dalam kejadian stroke pada data ini.

## Distribusi Pasien Stroke berdasarkan Riwayat Penyakit Jantung
"""

plt.subplots(figsize=(6, 6))

labels = "No","Yes"
size = 0.5

wedges, texts, autotexts = plt.pie([df[df["stroke"] == "Yes"]["heart_disease"].value_counts(ascending=False).values[0],
                                    df[df["stroke"] == "Yes"]["heart_disease"].value_counts(ascending=False).values[1]],
                                    explode = (0,0),
                                    textprops=dict(size= 18, color= "white"),
                                    autopct="%.2f%%",
                                    pctdistance = 0.72,
                                    radius=.9,
                                    colors = palette[0:2],
                                    shadow = True,
                                    wedgeprops=dict(width = size, edgecolor = "black",
                                    linewidth = 4),
                                    startangle = 35)

plt.legend(wedges, labels, title="Heart Disease",loc="center left",bbox_to_anchor=(1, 0, 0.5, 1), edgecolor = "black")
plt.title("\nPasien Stroke berdasarkan Penyakit Jantung",fontsize=20)
plt.show()

"""**Penjelasan insight:** Berdasarkan output diagram di atas, terlihat bahwa dari seluruh pasien stroke, sekitar 81,12% tidak memiliki riwayat penyakit jantung, sedangkan 18,88% pasien stroke memiliki penyakit jantung. Hal ini menunjukkan bahwa sebagian besar kasus stroke pada dataset ini terjadi pada individu tanpa penyakit jantung. Namun, proporsi hampir satu dari lima pasien stroke memiliki riwayat penyakit jantung, yang tetap menunjukkan adanya keterkaitan antara penyakit jantung dan risiko terjadinya stroke, meskipun bukan faktor dominan di antara seluruh pasien.

## Distribusi Pasien Stroke berdasarkan Tipe Pekerjaan
"""

plt.subplots(figsize=(12, 4))
p=sns.countplot(y=df[df["stroke"]=="Yes"]["work_type"],order=df[df["stroke"]=="Yes"]["work_type"].value_counts(ascending=False).index,palette="husl", saturation=1, edgecolor = "#1c1c1c", linewidth = 5)
p.axes.set_title("\nPasien Stroke berdasarkan Tipe Pekerjaan\n",fontsize=20)
p.axes.set_ylabel("Type",fontsize=16)
p.axes.set_xlabel("\nTotal",fontsize=16)
p.axes.set_yticklabels(p.get_yticklabels(),rotation = 0)
for container in p.containers:
    p.bar_label(container,label_type="center",padding=6,size=16,color="black",rotation=0,
    bbox={"boxstyle": "round", "pad": 0.2, "facecolor": "#e0b583", "edgecolor": "#1c1c1c", "linewidth" : 4, "alpha": 1})


sns.despine(left=True, bottom=True)
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik output di atas, ien yang bekerja secara mandiri (Self-employed), 33 pasien dengan pekerjaan sebagai pegawai negeri atau pemerintahan (Govt_job), serta 2 pasien yang masih berstatus anak-anak (children). Hal ini menunjukkan bahwa penderita stroke paling banyak berasal dari kalangan pekerja swasta, yang kemungkinan memiliki tingkat stres kerja atau pola hidup tertentu yang berkontribusi terhadap risiko stroke.

## Distribusi Pasien Stroke berdasarkan Kadar Glukosa Rata-rata
"""

plt.subplots(figsize=(12, 4))
p = sns.histplot(data=df[df["stroke"]=="Yes"],x="avg_glucose_level",hue="gender",multiple="stack",palette=palette[0:2],kde=True,bins=30,alpha=1,fill=True,edgecolor="black",linewidth=3)
p.axes.lines[0].set_color(palette[1])
p.axes.lines[1].set_color(palette[0])
p.axes.set_title("\nDistribusi Pasien Stroke berdasarkan Kadar Glukosa Rata-rata\n",fontsize=20)
p.set_ylabel("Count",fontsize=18)
p.set_xlabel("\nAverage Glucose Level",fontsize=18)
p.set_yscale("linear")
sns.despine(left=True, bottom=True)

plt.show()

"""**Penjelasan insight:** Berdasarkan output grafik di atas, terlihat bahwa distribusi kadar glukosa rata-rata pada pasien stroke untuk laki-laki dan perempuan memiliki pola yang mirip, dengan sebagian besar pasien memiliki kadar glukosa di bawah 125 mg/dL. Namun, terdapat juga beberapa pasien dengan kadar glukosa yang sangat tinggi, bahkan melebihi 200 mg/dL, meskipun jumlahnya lebih sedikit. Pola ini menunjukkan bahwa sebagian besar pasien stroke berada pada rentang kadar glukosa normal hingga sedikit tinggi, tetapi ada kelompok kecil dengan kadar glukosa sangat tinggi yang berpotensi mengindikasikan kondisi seperti diabetes, yang dapat meningkatkan risiko terjadinya stroke.

## Correlation Heatmap
"""

catcol = [col for col in df.columns if df[col].dtype == "object"]
le = LabelEncoder()
for col in catcol:
    df[col] = le.fit_transform(df[col].astype(str))

if 'id' in df.columns:
    df = df.drop(columns=['id'])

plt.figure(figsize=(10, 8))
sns.heatmap(
    df.corr(numeric_only=True),
    cmap="coolwarm",
    annot=True,
    fmt=".2f",
    square=True,
    cbar_kws=dict(shrink=.8),
    vmin=-1,
    vmax=1,
    linewidths=1.5,
    linecolor='white',
    annot_kws={'size': 10}
)

plt.title("Pearson Correlation of Features", fontsize=22, pad=15)
plt.xticks(rotation=45, ha='right', fontsize=10)
plt.yticks(rotation=0, fontsize=10)
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Dari heatmap korelasi di atas, terlihat bahwa sebagian besar fitur memiliki hubungan yang lemah satu sama lain, artinya tidak ada multikolinearitas yang signifikan antar variabel. Korelasi tertinggi muncul antara age dan ever_married (sekitar 0.68), menunjukkan bahwa semakin tua seseorang, semakin besar kemungkinan ia sudah menikah. Fitur age, hypertension, dan heart_disease memiliki korelasi positif lemah dengan stroke, menandakan bahwa risiko stroke cenderung meningkat seiring bertambahnya usia dan adanya kondisi hipertensi atau penyakit jantung. Sementara itu, fitur lain seperti work_type, Residence_type, dan smoking_status tampak memiliki korelasi yang sangat kecil dengan stroke, sehingga mungkin tidak terlalu berpengaruh secara langsung terhadap kejadian stroke dalam dataset ini.

## Data Splitting
"""

X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42, stratify=y)

X_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)

print("Ukuran masing-masing subset:")
print(f"X_train: {X_train.shape}")
print(f"X_valid: {X_valid.shape}")
print(f"X_test : {X_test.shape}")
print(f"y_valid: {y_valid.shape}")
print(f"y_test : {y_test.shape}")

"""**Penjelasan insight:** Setelah dilakukannya train test validation split, yaitu 4.088 sampel untuk pelatihan, 511 sampel untuk validasi, dan 511 sampel untuk pengujian, masing-masing memiliki 16 fitur.

## Imbalance dataset Handling
"""

y_train.value_counts()

smote = SMOTE(random_state=42)
X_train_bal, y_train_bal = smote.fit_resample(X_train, y_train)

print("Jumlah data sebelumnya:",len(X_train))
print("Jumlah data setelah pake oversampler:",len(X_train_bal))

y_train_bal.value_counts()

before = Counter(y_train)
after = Counter(y_train_bal)

fig, axes = plt.subplots(1, 2, figsize=(10, 4))

# Sebelum oversampling
sns.barplot(x=list(before.keys()), y=list(before.values()), ax=axes[0], palette="pastel")
axes[0].set_title("Sebelum Oversampling", fontsize=14)
axes[0].set_xlabel("Kelas")
axes[0].set_ylabel("Jumlah Sampel")

# Sesudah oversampling
sns.barplot(x=list(after.keys()), y=list(after.values()), ax=axes[1], palette="crest")
axes[1].set_title("Sesudah Oversampling (SMOTE)", fontsize=14)
axes[1].set_xlabel("Kelas")
axes[1].set_ylabel("Jumlah Sampel")

plt.suptitle("Perbandingan Distribusi Kelas Sebelum dan Sesudah SMOTE", fontsize=16, y=1.05)
plt.tight_layout()
plt.show()

"""**Penjelasan insight:** Dari grafik di atas menunjukkan bahwa sebelum dilakukan oversampling dengan SMOTE, data sangat tidak seimbang, kelas 0 memiliki jumlah sampel yang jauh lebih banyak dibandingkan kelas 1. Setelah penerapan SMOTE, jumlah sampel pada kedua kelas menjadi hampir sama besar, menandakan bahwa data kini sudah balanced. Hal ini penting karena model machine learning akan memiliki kesempatan yang lebih adil untuk belajar mengenali pola dari kedua kelas, sehingga dapat mengurangi bias terhadap kelas mayoritas dan meningkatkan kemampuan model dalam mendeteksi kelas minoritas.

## Scaling Data
"""

scaler = StandardScaler()
X_train_bal_scaled = scaler.fit_transform(X_train_bal)
X_valid_scaled = scaler.transform(X_valid)

"""# Modeling

## Random Forest
"""

rf_model = RandomForestClassifier(
    n_estimators=100,
    random_state=42
)
rf_model.fit(X_train_bal_scaled, y_train_bal)

y_pred_rf = rf_model.predict(X_valid_scaled)
print("Random Forest")
print("Akurasi:", accuracy_score(y_valid, y_pred_rf))
print(classification_report(y_valid, y_pred_rf))

print("Random Forest")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_rf):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_rf):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_rf):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_rf):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_rf):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_rf)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight yaitu sebagai berikut:
1. True Negative sebanyak 441 sampel, artinya model memprediksi tidak stroke dan benar tidak stroke.
2. False Positif sebanyak 45 sampel, artinya model memprediksi stroke padahal sebenarnya tidak stroke, jadi 45 orang tersebut merupakan salah prediksi dari model. Namun karena diprediksi stroke, 45 orang tersebut bisa lebih aware dan menjaga pola hidup agar terhindar dari stroke.
3. False Negative sebanyak 17 sampel, artinya model memprediksi tidak stroke tapi ternyata sebenarnya pasien tersebut stroke, hal ini cukup penting dan bisa menyebabkan bias pada model karena kasus sebenarnya terlewat.
4. True Positive sebanyak 8 sampel, artinya model memprediksi stroke dan benar mereka mengalami stroke.

Dapat disimpulkan bahwa model cukup baik mengenali orang yang tidak stroke karena angka 441 tergolong besar, tetapi lemah dalam mendeteksi kasus stroke yang hanya terdeteksi benar 8 dari total 25 kasus sebenarnya. Dengan demikian, hal tersebut bisa dikatakan bahwa prediksi menggunakan model random forest kurang sensitif terhadap kasus stroke, dan bisa berisiko jika diterapkan di dunia nyata karena banyak kasus stroke yang lolos dari deteksi model.

## Support Vector Machine
"""

svm_model = SVC(kernel='rbf', C=1, gamma='scale', probability=True, random_state=42)
svm_model.fit(X_train_bal_scaled, y_train_bal)

y_pred_svm = svm_model.predict(X_valid_scaled)

print("Support Vector Machine")
print("Akurasi:", accuracy_score(y_valid, y_pred_svm))
print(classification_report(y_valid, y_pred_svm))

print("\nSupport Vector Machine (SVM)")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_svm):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_svm):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_svm):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_svm):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_svm):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_svm)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight yaitu sebagai berikut:
1. True Negative sebanyak 389 sampel, artinya model memprediksi tidak stroke dan benar tidak stroke.
2. False Positive sebanyak 97 sampel, artinya model memprediksi stroke padahal sebenarnya tidak stroke. Meskipun termasuk salah prediksi, orang-orang ini justru bisa menjadi lebih waspada dan mulai memperhatikan kesehatan agar terhindar dari risiko stroke.
3. False Negative sebanyak 11 sampel, artinya model memprediksi tidak stroke namun sebenarnya pasien tersebut mengalami stroke. Hal ini cukup penting karena kasus sebenarnya terlewat dan dapat menyebabkan bias pada hasil prediksi model.
4. True Positive sebanyak 14 sampel, artinya model memprediksi stroke dan benar-benar stroke.

Dapat disimpulkan bahwa model masih lebih baik dalam mengenali orang yang tidak stroke dibandingkan dengan yang stroke. Namun dibanding model sebelumnya, performa dalam mendeteksi kasus stroke sedikit meningkat (14 benar dari total 25 kasus sebenarnya). Meskipun demikian, nilai False Positive yang tinggi (97) menunjukkan bahwa model cukup sering salah memprediksi orang sehat sebagai stroke. Dengan demikian, model ini sedikit lebih sensitif terhadap kasus stroke, tetapi masih perlu perbaikan agar keseimbangan antara sensitivitas dan akurasi keseluruhan menjadi lebih optimal.

## Simpe Artificial Neural Network (ANN)
"""

ann_model = Sequential([
    Dense(32, activation='relu', input_shape=(X_train_bal_scaled.shape[1],)),
    Dropout(0.3),
    Dense(16, activation='relu'),
    Dense(1, activation='sigmoid')
])

ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

history = ann_model.fit(
    X_train_bal_scaled, y_train_bal,
    validation_data=(X_valid_scaled, y_valid),
    epochs=50, batch_size=32, verbose=0
)
y_pred_ann = (ann_model.predict(X_valid_scaled) > 0.5).astype("int32")

print("Simple ANN")
print("Akurasi:", accuracy_score(y_valid, y_pred_ann))
print(classification_report(y_valid, y_pred_ann))

print("\nSimple ANN")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_ann):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_ann):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_ann):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_ann):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_ann):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_ann)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight yaitu sebagai berikut:
1. True Negative sebanyak 414 sampel, artinya model memprediksi tidak stroke dan benar tidak stroke.
2. False Positive sebanyak 72 sampel, artinya model memprediksi stroke padahal sebenarnya tidak stroke. Walaupun termasuk salah prediksi, hal ini masih dapat berdampak positif karena orang yang diprediksi stroke dapat lebih berhati-hati dan menjaga gaya hidupnya.
3. False Negative sebanyak 15 sampel, artinya model memprediksi tidak stroke namun sebenarnya pasien tersebut mengalami stroke. Hal ini cukup penting karena kasus stroke sebenarnya tidak terdeteksi oleh model.
4. True Positive sebanyak 10 sampel, artinya model memprediksi stroke dan benar-benar stroke.

Dapat disimpulkan bahwa model lebih akurat dalam mengenali orang yang tidak stroke (karena nilai True Negative tinggi), namun masih kurang optimal dalam mendeteksi kasus stroke (hanya 10 dari total 25 kasus sebenarnya). Dibandingkan model sebelumnya, model Simple ANN menunjukkan sedikit peningkatan dalam mengenali kasus stroke dibanding model pertama, namun masih perlu ditingkatkan sensitivitasnya agar lebih mampu mendeteksi kasus stroke secara tepat tanpa terlalu banyak menghasilkan False Positive.

## Decision Tree
"""

from sklearn.tree import DecisionTreeClassifier

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train_bal_scaled, y_train_bal)
y_pred_dt = dt_model.predict(X_valid_scaled)

print("Decision Tree")
print("Akurasi:", accuracy_score(y_valid, y_pred_dt))
print(classification_report(y_valid, y_pred_dt))

print("\nDecision Tree")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_dt):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_dt):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_dt):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_dt):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_dt):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_dt)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight yaitu sebagai berikut:
1. True Negative (TN) sebanyak 430 sampel, artinya model memprediksi kelas tidak stroke dan benar-benar tidak stroke. Ini menunjukkan bahwa model cukup baik dalam mengenali data negatif.
2. False Positive (FP) sebanyak 56 sampel, artinya model memprediksi kelas stroke padahal sebenarnya tidak stroke. Kesalahan ini bisa berdampak pada peningkatan jumlah prediksi positif palsu.
3. False Negative (FN) sebanyak 16 sampel, artinya model memprediksi tidak stroke namun sebenarnya stroke. Ini merupakan kesalahan yang cukup penting karena model gagal mendeteksi kasus positif yang sebenarnya.
4. True Positive (TP) sebanyak 9 sampel, artinya model memprediksi stroke dan benar-benar stroke.

Dari hasil tersebut, dapat disimpulkan bahwa Decision Tree model lebih akurat dalam mengenali kelas negatif (tidak stroke) karena nilai True Negative jauh lebih tinggi dibanding True Positive. Namun, model masih kurang optimal dalam mendeteksi kelas positif (stroke) karena jumlah True Positive yang rendah dan False Negative yang cukup tinggi. Secara keseluruhan, model menunjukkan kecenderungan overfitting terhadap kelas mayoritas, sehingga perlu dilakukan peningkatan sensitivitas (recall) terhadap kelas minoritas, misalnya dengan melakukan penyeimbangan data (oversampling/undersampling) atau penyesuaian parameter model agar lebih mampu mendeteksi kasus positif secara akurat.

## Logistic Regression
"""

from sklearn.linear_model import LogisticRegression

log_model = LogisticRegression(max_iter=500, random_state=42)
log_model.fit(X_train_bal_scaled, y_train_bal)
y_pred_log = log_model.predict(X_valid_scaled)

print("Logistic Regression")
print("Akurasi:", accuracy_score(y_valid, y_pred_log))
print(classification_report(y_valid, y_pred_log))

print("\nLogistic Regression")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_log):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_log):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_log):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_log):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_log):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_log)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight sebagai berikut:
1. True Negative (TN) sebanyak 372 sampel, artinya model memprediksi tidak stroke dan benar-benar tidak stroke. Ini menunjukkan model cukup baik dalam mengenali pasien yang sehat atau tidak mengalami stroke.
2. False Positive (FP) sebanyak 114 sampel, artinya model memprediksi stroke padahal sebenarnya tidak stroke. Kesalahan ini masih bisa dimaklumi karena walaupun salah prediksi, pasien yang dikira berisiko stroke bisa menjadi lebih waspada dan menjaga kesehatannya.
3. False Negative (FN) sebanyak 3 sampel, artinya model memprediksi tidak stroke namun sebenarnya pasien tersebut mengalami stroke. Ini termasuk kesalahan yang cukup penting karena dapat menyebabkan kasus stroke sebenarnya tidak terdeteksi.
4. True Positive (TP) sebanyak 22 sampel, artinya model memprediksi stroke dan benar-benar stroke.

Dapat disimpulkan bahwa model Logistic Regression memiliki kinerja yang cukup baik dalam mengenali pasien yang tidak stroke (TN tinggi), namun masih menghasilkan cukup banyak prediksi stroke yang keliru (FP tinggi). Di sisi lain, jumlah kasus stroke yang tidak terdeteksi (FN) relatif kecil, yang berarti model cukup sensitif dalam mendeteksi kasus stroke.

## K-Nearest Neighbors
"""

from sklearn.neighbors import KNeighborsClassifier

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train_bal_scaled, y_train_bal)
y_pred_knn = knn_model.predict(X_valid_scaled)

print("K-Nearest Neighbors")
print("Akurasi:", accuracy_score(y_valid, y_pred_knn))
print(classification_report(y_valid, y_pred_knn))

print("\nK-Nearest Neighbors")
print(f"Akurasi  : {accuracy_score(y_valid, y_pred_knn):.4f}")
print(f"Presisi  : {precision_score(y_valid, y_pred_knn):.4f}")
print(f"Recall   : {recall_score(y_valid, y_pred_knn):.4f}")
print(f"F1-score : {f1_score(y_valid, y_pred_knn):.4f}")
print(f"ROC-AUC  : {roc_auc_score(y_valid, y_pred_knn):.4f}")

conf_matrix = confusion_matrix(y_valid, y_pred_knn)
sns.heatmap(conf_matrix, annot=True, fmt='d')

"""**Penjelasan insight:** Berdasarkan confusion matrix di atas, diperoleh beberapa insight sebagai berikut:
1. True Negative (TN) sebanyak 403 sampel, artinya model memprediksi tidak stroke dan benar-benar tidak stroke. Ini menunjukkan model cukup andal dalam mengenali pasien yang sehat atau tidak mengalami stroke.
2. False Positive (FP) sebanyak 83 sampel, artinya model memprediksi stroke padahal sebenarnya tidak stroke. Meskipun termasuk kesalahan, hal ini masih memiliki sisi positif karena pasien yang diprediksi berisiko stroke dapat lebih berhati-hati terhadap kesehatannya.
3. False Negative (FN) sebanyak 14 sampel, artinya model memprediksi tidak stroke namun sebenarnya pasien tersebut mengalami stroke. Ini merupakan kesalahan yang penting karena kasus stroke sebenarnya tidak terdeteksi oleh model.
4. True Positive (TP) sebanyak 11 sampel, artinya model memprediksi stroke dan benar-benar stroke.

Dari hasil tersebut, dapat disimpulkan bahwa model K-Nearest Neighbors (KNN) memiliki performa yang cukup baik dalam mengenali pasien yang tidak stroke (TN tinggi), tetapi masih kurang optimal dalam mendeteksi pasien yang benar-benar stroke (TP rendah). Secara keseluruhan, model KNN lebih condong pada prediksi kelas mayoritas (tidak stroke), sehingga sensitivitas terhadap kasus stroke masih rendah. Untuk meningkatkan performa, dapat dilakukan setting n_neighbors atau penyeimbangan data agar model lebih seimbang dalam mendeteksi kedua kelas.

# Advanced Metrics
"""

models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='rbf', probability=True, random_state=42),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Logistic Regression": LogisticRegression(max_iter=500, random_state=42),
    "KNN": KNeighborsClassifier(n_neighbors=5)
}

from sklearn.model_selection import cross_val_score, StratifiedKFold

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

results = {}

for name, model in models.items():
    print(f"\n{name}")

for name, model in models.items():
    model.fit(X_train_bal_scaled, y_train_bal)
    y_pred = model.predict(X_valid_scaled)
    y_proba = model.predict_proba(X_valid_scaled)[:, 1]

    acc = accuracy_score(y_valid, y_pred)
    prec = precision_score(y_valid, y_pred)
    rec = recall_score(y_valid, y_pred)
    f1 = f1_score(y_valid, y_pred)
    roc_auc = roc_auc_score(y_valid, y_proba)

    results[name] = [acc, prec, rec, f1, roc_auc]

df_results = pd.DataFrame(results, index=['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC-AUC']).T

df_results["Mean Score"] = df_results.mean(axis=1)

print("\nPerbandingan Performa Model")
display(df_results.sort_values(by="Mean Score", ascending=False))

"""**Penjelasan inisght:** Berdasarkan tabel perbandingan performa model di atas, dapat diperoleh beberapa insight sebagai berikut:
1. Akurasi tertinggi diperoleh oleh Random Forest (0.8787), diikuti oleh Decision Tree (0.8591) dan KNN (0.8102). Hal ini menunjukkan bahwa model berbasis pohon cenderung lebih kuat dalam mengenali pola data secara umum dibanding model lainnya.
2. Recall tertinggi dimiliki oleh Logistic Regression (0.88), jauh di atas model lainnya. Artinya, model ini paling baik dalam mendeteksi kasus stroke sebenarnya (true positive), meskipun akurasinya tidak tertinggi. Dalam konteks medis, recall yang tinggi sangat penting karena menurunkan risiko terlewatnya pasien yang benar-benar stroke.
3. Precision tertinggi juga dimiliki oleh Logistic Regression (0.1618), meskipun nilainya masih relatif rendah. Hal ini berarti sebagian besar prediksi “stroke” oleh model masih mengandung kesalahan (false positive) yang cukup banyak.
4. F1-score tertinggi juga dicapai oleh Logistic Regression (0.2733), yang menandakan keseimbangan terbaik antara precision dan recall di antara semua model.
5. ROC-AUC tertinggi adalah Logistic Regression (0.8805), menunjukkan kemampuan diskriminatif yang paling baik dalam membedakan antara pasien stroke dan tidak stroke.
6. Jika dilihat dari Mean Score (rata-rata metrik keseluruhan), Logistic Regression (0.5933) juga menempati posisi terbaik, menunjukkan performa yang paling seimbang dibanding model lainnya.

Dapat disimpulkan bahwa eskipun Random Forest memiliki akurasi tertinggi, Logistic Regression memberikan performa paling seimbang dan sensitif terhadap kasus stroke (recall tertinggi dan ROC-AUC tinggi). Dalam hal ini model Logistic Regression bisa cocok digunakan untuk deteksi stroke, karena dapat menangkap sebanyak mungkin kasus positif lebih penting daripada sekadar meningkatkan akurasi keseluruhan.
"""

plt.figure(figsize=(10,6))
sns.barplot(data=df_results.reset_index(), x="Mean Score", y="index", palette="coolwarm")
plt.title("Perbandingan Rata-Rata Performa Model", fontsize=14)
plt.xlabel("Rata-rata Skor (0-1)")
plt.ylabel("Model")
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik di atas, dapat dilihat bahwa Logistic Regression memiliki nilai rata-rata performa tertinggi dibanding model lainnya, menunjukkan bahwa model ini paling seimbang dan konsisten dalam mendeteksi kasus stroke. Model SVM dan Random Forest menempati posisi berikutnya dengan performa yang cukup baik, sedangkan KNN dan Decision Tree memiliki skor rata-rata yang lebih rendah. Secara keseluruhan, Logistic Regression menjadi model paling optimal dalam mendeteksi stroke berdasarkan kombinasi metrik evaluasi yang digunakan."""

from sklearn.metrics import roc_curve, roc_auc_score

plt.figure(figsize=(8,6))
for name, model in models.items():
    y_proba = model.predict_proba(X_valid_scaled)[:, 1]
    fpr, tpr, _ = roc_curve(y_valid, y_proba)
    plt.plot(fpr, tpr, label=f"{name} (AUC = {roc_auc_score(y_valid, y_proba):.2f})")
plt.plot([0, 1], [0, 1], 'k--')
plt.title("Perbandingan ROC Curve Antar Model")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.legend()
plt.show()

"""**Penjelasan insight:** Berdasarkan grafik di atas, dapat dilihat bahwa Logistic Regression memiliki nilai rata-rata performa tertinggi dibanding model lainnya, menunjukkan bahwa model ini paling seimbang dan konsisten dalam mendeteksi kasus stroke. Model SVM dan Random Forest menempati posisi berikutnya dengan performa yang cukup baik, sedangkan KNN dan Decision Tree memiliki skor rata-rata yang lebih rendah. Secara keseluruhan, Logistic Regression menjadi model paling optimal dalam mendeteksi stroke berdasarkan kombinasi metrik evaluasi yang digunakan.

# Cross Validation
"""

from sklearn.model_selection import cross_val_score

scores = cross_val_score(log_model, X_train_bal_scaled, y_train_bal, cv=5)
print(f"CV Scores: {scores}")
print(f"Mean: {scores.mean()} (±{scores.std()})")

"""**Penjelasan insight:** Berdasarkan hasil Cross-Validation (CV), diperoleh skor pada setiap fold sebesar [0.7686, 0.8040, 0.8162, 0.8206, dan 0.8199] dengan rata-rata skor 0.8059 dan standar deviasi ±0.0195. Nilai rata-rata yang cukup tinggi dan variasi yang kecil menunjukkan bahwa model memiliki kinerja yang stabil dan konsisten di berbagai subset data. Hal ini menandakan bahwa model tidak overfitting dan mampu memberikan performa yang baik ketika diuji pada data yang berbeda.

# Hyperparameter Tuning

## Random Forest Tuning
"""

from imblearn.pipeline import Pipeline

rf_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),
    ('rf', RandomForestClassifier(class_weight='balanced', random_state=42))
])

param_grid = {
    'rf__n_estimators': [100, 200],
    'rf__max_depth': [None, 10, 20],
    'rf__min_samples_split': [2, 10]
}

grid_rf = GridSearchCV(
    rf_pipe,
    param_grid,
    scoring='recall_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_rf.fit(X_train, y_train)

print("Best Params:", grid_rf.best_params_)
print("Best Recall Macro Score:", grid_rf.best_score_)

"""### Re-trained Random Forest after Tuning

"""

best_rf = grid_rf.best_estimator_
y_pred = best_rf.predict(X_valid)

print("\nFinal Evaluation on Validation Set")
print("Akurasi :", accuracy_score(y_valid, y_pred))
print(confusion_matrix(y_valid, y_pred))
print(classification_report(y_valid, y_pred))

"""**Penjelasan insight:** Berdasarkan hasil evaluasi sebelum dan sesudah tuning, terlihat bahwa terjadi perubahan keseimbangan performa model Random Forest setelah dilakukan penyesuaian parameter.

Sebelum tuning, model memiliki akurasi tinggi (0.8787) namun recall untuk kelas stroke hanya 0.32, artinya model masih kesulitan mendeteksi pasien yang benar-benar mengalami stroke. Model lebih fokus mengenali kelas mayoritas (tidak stroke), sehingga meskipun akurasi tinggi, kemampuan mendeteksi kasus stroke (kelas minoritas) masih rendah. Setelah dilakukan tuning, akurasi memang sedikit menurun menjadi 0.8023, tetapi recall untuk kelas stroke meningkat signifikan dari 0.32 menjadi 0.44. Artinya, model menjadi lebih sensitif terhadap kasus stroke, mampu menangkap lebih banyak pasien yang benar-benar mengalami stroke meskipun dengan trade-off berupa sedikit penurunan akurasi keseluruhan.

Secara keseluruhan, hasil tuning membuat model menjadi lebih seimbang, meskipun akurasi total turun, kemampuan model dalam mendeteksi kasus stroke meningkat, yang sangat penting dalam konteks medis di mana mencegah kesalahan deteksi (false negative) jauh lebih krusial daripada sekadar menjaga akurasi tinggi.

## Support Vector Machine (SVM) Tuning
"""

svm_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),
    ('svm', SVC(class_weight='balanced', random_state=42))
])

param_svm = {
    'svm__C': [0.1, 1, 10],
    'svm__kernel': ['linear', 'rbf', 'poly'],
    'svm__gamma': ['scale', 'auto']
}

grid_svm = GridSearchCV(
    svm_pipe,
    param_grid=param_svm,
    scoring='recall_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_svm.fit(X_train, y_train)

print("Best SVM Params:", grid_svm.best_params_)
print("Best SVM Score :", grid_svm.best_score_)

"""### Re-trained SVM Model after Tuning

"""

best_svm = grid_svm.best_estimator_
y_pred_svm = best_svm.predict(X_valid)

print("\nFinal Evaluation on Validation Set (SVM)")
print("Akurasi :", accuracy_score(y_valid, y_pred_svm))
print(confusion_matrix(y_valid, y_pred_svm))
print(classification_report(y_valid, y_pred_svm))

"""**Penjelasan insight:** Berdasarkan hasil evaluasi model Support Vector Machine (SVM) sebelum dan sesudah tuning, terlihat adanya perubahan fokus performa model yang cukup signifikan.
Sebelum tuning, model memiliki akurasi 0.7886 dengan recall untuk kelas stroke sebesar 0.56 dan precision sebesar 0.13. Ini menunjukkan bahwa model sudah cukup baik dalam mengenali kasus stroke, namun masih menghasilkan banyak prediksi positif yang salah (false positive). Setelah tuning, akurasi memang menurun menjadi 0.7221, namun recall kelas stroke meningkat drastis menjadi 0.88. Artinya, model menjadi jauh lebih sensitif dalam mendeteksi pasien yang benar-benar mengalami stroke, hampir semua kasus stroke berhasil teridentifikasi. Namun, peningkatan recall ini datang dengan penurunan precision (0.14), menandakan bahwa model kini juga lebih sering salah mengira pasien tidak stroke sebagai stroke.

Secara keseluruhan, setelah tuning, SVM menjadi jauh lebih baik dalam menangkap kasus stroke (recall tinggi) meskipun akurasinya menurun. Dalam konteks deteksi medis, ini merupakan peningkatan yang positif karena lebih baik mendeteksi terlalu banyak daripada melewatkan pasien yang benar-benar stroke, sehingga model pasca-tuning lebih bermanfaat untuk tujuan deteksi dini dan pencegahan risiko stroke.

## Decision Tree Tuning
"""

dt_pipe = Pipeline([
    ('scaler', StandardScaler()),  # optional tapi bagus untuk konsistensi antar model
    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),
    ('dt', DecisionTreeClassifier(class_weight='balanced', random_state=42))
])

param_dt = {
    'dt__criterion': ['gini', 'entropy'],
    'dt__max_depth': [None, 5, 10, 20],
    'dt__min_samples_split': [2, 5, 10],
    'dt__min_samples_leaf': [1, 2, 5]
}

grid_dt = GridSearchCV(
    dt_pipe,
    param_grid=param_dt,
    scoring='recall_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_dt.fit(X_train, y_train)

print("Best DT Params:", grid_dt.best_params_)
print("Best DT Score :", grid_dt.best_score_)

"""### Re-trained Decision Tree Model after Tuning"""

best_dt = grid_dt.best_estimator_
y_pred_dt = best_dt.predict(X_valid)

print("\nFinal Evaluation on Validation Set (Decision Tree)")
print("Akurasi :", accuracy_score(y_valid, y_pred_dt))
print(confusion_matrix(y_valid, y_pred_dt))
print(classification_report(y_valid, y_pred_dt))

"""**Penjelasan insight:** Berdasarkan hasil evaluasi, model Decision Tree sebelum tuning memiliki akurasi 0.859, dengan precision 0.14 dan recall 0.36 untuk kelas stroke. Hal ini menunjukkan bahwa model cukup baik dalam mengenali pasien tidak stroke, tetapi masih lemah dalam mendeteksi pasien stroke karena recall yang rendah. Setelah dilakukan hyperparameter tuning, akurasi model memang menurun menjadi 0.677, namun recall untuk kelas stroke meningkat signifikan dari 0.36 menjadi 0.92. Artinya, model yang sudah dituning menjadi jauh lebih sensitif terhadap kasus stroke, meskipun menghasilkan lebih banyak prediksi salah (precision rendah). Secara keseluruhan, tuning membuat model lebih seimbang dalam mendeteksi kasus stroke, karena kini lebih mampu menangkap pasien yang benar-benar stroke, meskipun dengan konsekuensi penurunan akurasi keseluruhan.

## Logistic Regression Tuning
"""

lr_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),
    ('lr', LogisticRegression(class_weight='balanced', max_iter=500, random_state=42))
])

param_lr = {
    'lr__penalty': ['l1', 'l2', 'elasticnet', None],
    'lr__solver': ['liblinear', 'saga'],
    'lr__C': [0.01, 0.1, 1, 10],
    'lr__l1_ratio': [0, 0.5, 1]
}

grid_lr = GridSearchCV(
    lr_pipe,
    param_grid=param_lr,
    scoring='recall_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_lr.fit(X_train, y_train)

print("Best Logistic Regression Params:", grid_lr.best_params_)
print("Best Logistic Regression Score :", grid_lr.best_score_)

"""### Re-trained Logistic Regression after Tuning"""

best_lr = grid_lr.best_estimator_
y_pred_lr = best_lr.predict(X_valid)

print("\nFinal Evaluation on Validation Set (Logistic Regression)")
print("Akurasi :", accuracy_score(y_valid, y_pred_lr))
print(confusion_matrix(y_valid, y_pred_lr))
print(classification_report(y_valid, y_pred_lr))

"""**Penjelasan insight:** Berdasarkan hasil evaluasi, model Logistic Regression sebelum tuning memiliki akurasi 0.77 dengan recall tinggi (0.88) pada kelas stroke dan precision 0.16. Hal ini menunjukkan bahwa model cukup baik dalam mendeteksi pasien yang benar-benar stroke, meskipun masih menghasilkan beberapa kesalahan prediksi positif (false positive). Setelah dilakukan hyperparameter tuning, akurasi model menurun menjadi 0.71, namun recall tetap tinggi (0.88), yang berarti model tetap mampu mendeteksi sebagian besar kasus stroke dengan baik. Meskipun ada penurunan akurasi dan precision, model hasil tuning menjadi lebih sensitif terhadap kasus stroke, yang penting dalam konteks medis untuk meminimalkan risiko pasien stroke yang tidak terdeteksi. Dengan kata lain, tuning membantu mempertahankan kemampuan deteksi yang kuat meski dengan sedikit kompromi pada ketepatan prediksi.

## KNN Tuning
"""

knn_pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('smote', SMOTE(random_state=42, sampling_strategy=0.5)),
    ('knn', KNeighborsClassifier())
])

param_knn = {
    'knn__n_neighbors': [3, 5, 7, 9, 11],
    'knn__weights': ['uniform', 'distance'],
    'knn__metric': ['euclidean', 'manhattan', 'minkowski'],
    'knn__p': [1, 2]
}

grid_knn = GridSearchCV(
    knn_pipe,
    param_grid=param_knn,
    scoring='recall_macro',
    cv=5,
    n_jobs=-1,
    verbose=1
)

grid_knn.fit(X_train, y_train)
print("Best KNN Params:", grid_knn.best_params_)
print("Best KNN Score :", grid_knn.best_score_)

"""### Re-trained KNN Model after Tuning"""

best_knn = grid_knn.best_estimator_
y_pred_knn = best_knn.predict(X_valid)

print("\nFinal Evaluation on Validation Set (KNN)")
print("Akurasi :", accuracy_score(y_valid, y_pred_knn))
print(confusion_matrix(y_valid, y_pred_knn))
print(classification_report(y_valid, y_pred_knn))

"""**Penjelasan insight:** Berdasarkan hasil evaluasi, model K-Nearest Neighbors (KNN) sebelum tuning memiliki akurasi 0.81, dengan recall 0.44 dan precision 0.12 untuk kelas stroke. Ini menunjukkan bahwa model cukup baik dalam mengenali pasien tidak stroke, namun masih terbatas dalam mendeteksi pasien stroke. Setelah dilakukan hyperparameter tuning, akurasi model sedikit meningkat menjadi 0.82, dengan recall 0.40 dan precision 0.11. Artinya, tuning membantu meningkatkan stabilitas dan akurasi keseluruhan model meskipun peningkatan kemampuan deteksi stroke tidak terlalu besar. Secara keseluruhan, model KNN yang telah dituning menjadi lebih konsisten dan sedikit lebih akurat, namun tetap perlu peningkatan lebih lanjut agar lebih sensitif dalam mendeteksi kasus stroke yang sebenarnya.

# Kesimpulan secara menyeluruh
Berdasarkan hasil evaluasi seluruh model setelah dilakukan pengujian pada data validasi, dapat disimpulkan bahwa setiap model memiliki keunggulan dan kelemahan masing-masing tergantung pada tujuan utama prediksi.

Model dengan akurasi tertinggi adalah Simple ANN (0.83), diikuti oleh KNN (0.82) dan Random Forest (0.80). Hal ini menunjukkan bahwa ketiga model tersebut memiliki kemampuan klasifikasi yang kuat secara keseluruhan. Namun, dari sisi recall kelas stroke, model SVM (0.88), Decision Tree (0.92), dan Logistic Regression (0.88) menunjukkan sensitivitas yang jauh lebih tinggi, artinya model tersebut lebih baik dalam mendeteksi pasien yang benar-benar mengalami stroke, meskipun akurasinya sedikit lebih rendah.

Dalam konteks medis seperti deteksi stroke, recall menjadi metrik yang paling penting, karena lebih baik menghasilkan sedikit kesalahan positif (false positive) daripada melewatkan pasien yang sebenarnya berisiko (false negative). Berdasarkan hal tersebut, model yang paling efektif secara praktis adalah Decision Tree setelah tuning, karena memiliki recall tertinggi (0.92) dan tetap menjaga precision yang cukup stabil.

Namun, jika mempertimbangkan keseimbangan antara akurasi dan recall, maka Simple ANN dapat dianggap sebagai model terbaik secara keseluruhan, karena memiliki akurasi tinggi (0.83) dan kinerja stabil tanpa kehilangan sensitivitas terlalu banyak.
"""